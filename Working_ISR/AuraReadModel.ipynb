{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "z5ODgQYoPcAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh16kStjxB0O"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import math\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse.linalg import svds\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.sparse import csr_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split into train and test"
      ],
      "metadata": {
        "id": "pctNq5v5PeSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_train_test_split(dataframe, min_interactions=3, test_size=0.30, random_state=42):\n",
        "    # Function to apply logarithmic smoothing to a value\n",
        "    def apply_log_smoothing(value):\n",
        "        return math.log(1 + value, 2)\n",
        "\n",
        "    # Group by ISBN and User-ID, count interactions, and summarize by user\n",
        "    interaction_summary = dataframe.groupby(['ISBN', 'User-ID']).size()\n",
        "    user_interaction_totals = interaction_summary.groupby('User-ID').size()\n",
        "    print(f'Total number of users: {len(user_interaction_totals)}')\n",
        "\n",
        "    # Filter users with at least 'min_interactions' interactions\n",
        "    qualified_users = user_interaction_totals[user_interaction_totals >= min_interactions].reset_index()[['User-ID']]\n",
        "    print(f'Users with at least {min_interactions} interactions: {len(qualified_users)}')\n",
        "\n",
        "    # Filter the dataset to include only interactions from qualified users\n",
        "    qualified_interactions = dataframe.merge(qualified_users, on='User-ID', how='right')\n",
        "    print(f'Total interactions: {len(dataframe)}')\n",
        "    print(f'Interactions from qualified users: {len(qualified_interactions)}')\n",
        "\n",
        "    # Apply smoothing to the sum of book ratings and reset the index\n",
        "    smoothed_interactions = qualified_interactions.groupby(['ISBN', 'User-ID'])['Book-Rating'].sum().apply(apply_log_smoothing).reset_index()\n",
        "    print(f'Unique user/item interactions: {len(smoothed_interactions)}')\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_data, test_data = train_test_split(smoothed_interactions,\n",
        "                                             stratify=smoothed_interactions['User-ID'],\n",
        "                                             test_size=test_size,\n",
        "                                             random_state=random_state)\n",
        "    print(f'Interactions on Train set: {len(train_data)}')\n",
        "    print(f'Interactions on Test set: {len(test_data)}')\n",
        "\n",
        "    return train_data, test_data, smoothed_interactions\n"
      ],
      "metadata": {
        "id": "lt1hVFtl4VTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVD"
      ],
      "metadata": {
        "id": "-69Ccq5sPj5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def matrix_factorization_predictions(train_df, num_factors=15):\n",
        "    \"\"\"Performs matrix factorization using SVD on the user-item ratings matrix from training data.\n",
        "\n",
        "    Args:\n",
        "        train_df (DataFrame): Training data containing user, item, and ratings.\n",
        "        num_factors (int): Number of latent factors to use in the matrix factorization.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: A DataFrame with the predicted ratings for all users and items.\n",
        "    \"\"\"\n",
        "    # Create pivot table\n",
        "    users_items_pivot_matrix_df = train_df.pivot(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
        "\n",
        "    # Convert the pivot table to a sparse matrix format\n",
        "    users_items_pivot_matrix = csr_matrix(users_items_pivot_matrix_df.values)\n",
        "\n",
        "    # Perform matrix factorization using SVD\n",
        "    U, sigma, Vt = svds(users_items_pivot_matrix, k=num_factors)\n",
        "    sigma = np.diag(sigma)\n",
        "\n",
        "    # Predict ratings\n",
        "    all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "\n",
        "    # Normalize the ratings to be between 0 and 10\n",
        "    min_val = np.min(all_user_predicted_ratings)\n",
        "    max_val = np.max(all_user_predicted_ratings)\n",
        "    all_user_predicted_ratings_norm = ((all_user_predicted_ratings - min_val) /\n",
        "                                       (max_val - min_val)) * 10\n",
        "\n",
        "    # Convert the matrix back to a DataFrame\n",
        "    cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, columns=users_items_pivot_matrix_df.columns, index=users_items_pivot_matrix_df.index).transpose()\n",
        "\n",
        "    return cf_preds_df\n",
        "\n"
      ],
      "metadata": {
        "id": "vRwYdYSbPmLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User based Collaborative Filtering using Matrix factorization"
      ],
      "metadata": {
        "id": "M36EdIz2PuBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming your CFRecommender class has a method recommend_items that can return ratings predictions\n",
        "# First, extend your CFRecommender class to include a method to predict ratings for a given user and item\n",
        "\n",
        "class CFRecommender:\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10):\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('recStrength', ascending=False).head(topn)\n",
        "        return recommendations_df\n",
        "\n",
        "    def predict_rating(self, user_id, item_id):\n",
        "        if user_id in self.cf_predictions_df.columns and item_id in self.cf_predictions_df.index:\n",
        "            return self.cf_predictions_df.loc[item_id, user_id]\n",
        "        else:\n",
        "            return np.nan  # Return NaN for user/item combinations not in the matrix\n"
      ],
      "metadata": {
        "id": "yqtsruXMPqSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelRecommender:\n",
        "\n",
        "    def __init__(self, interactions_full_indexed_df,interactions_test_indexed_df, interactions_train_indexed_df, ratings_df_unique ):\n",
        "        self.interactions_full_indexed_df = interactions_full_indexed_df\n",
        "        self.interactions_test_indexed_df = interactions_test_indexed_df\n",
        "        self.interactions_train_indexed_df = interactions_train_indexed_df\n",
        "        self.ratings_df_unique = ratings_df_unique\n",
        "\n",
        "    def get_items_interacted(UserID, interactions_df):\n",
        "      interacted_items = interactions_df.loc[UserID]['ISBN']\n",
        "      return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, UserID, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(UserID, self.interactions_full_indexed_df)\n",
        "        all_items = set(ratings_df['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "#\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id, mood):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = self.interactions_test_indexed_df.loc[person_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        #person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),topn=10000000000)\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=[],topn=10000000000)\n",
        "        updated_person_recs_df = person_recs_df.merge(self.ratings_df_unique[['ISBN', 'Max Mood', 'Book']], on='ISBN', how='left')\n",
        "        updated_person_recs_df = updated_person_recs_df[updated_person_recs_df['Max Mood'].str.contains(mood, na=False)]\n",
        "        #print('Recommendation for User-ID = ',person_id)\n",
        "        #print(updated_person_recs_df.head(10))\n",
        "        return updated_person_recs_df.head(5)\n",
        "\n",
        "        # Function to evaluate the performance of model at overall level\n",
        "    def recommend_book(self, model ,userid, mood):\n",
        "\n",
        "        person_metrics = self.evaluate_model_for_user(model, userid, mood)\n",
        "        return person_metrics\n",
        "\n",
        "#model_recommender = ModelRecommender()"
      ],
      "metadata": {
        "id": "RS74RxicP1LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RMSE"
      ],
      "metadata": {
        "id": "1TrvB0e49liX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rmse(test_df, cf_recommender_model):\n",
        "  # Now, predict ratings for all user-item pairs in the test set\n",
        "  test_users = test_df['User-ID']\n",
        "  test_items = test_df['ISBN']\n",
        "  predicted_ratings = [cf_recommender_model.predict_rating(user, item) for user, item in zip(test_users, test_items)]\n",
        "\n",
        "  # Add these predictions back to the test dataframe\n",
        "  test_df['predicted_rating'] = predicted_ratings\n",
        "\n",
        "  # Calculate RMSE\n",
        "  rmse = np.sqrt(mean_squared_error(test_df['Book-Rating'], test_df['predicted_rating'].fillna(0)))\n",
        "  print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "jY9ko6psSLoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BUILD model"
      ],
      "metadata": {
        "id": "PfRY5e6hQJTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to build the model.\n",
        "def build_model():\n",
        "  ratings_df = pd.read_csv(\"/content/baseline_ratinsg.csv\")\n",
        "  ratings_df.head()\n",
        "  ratings_df.rename(columns={'user_id':'User-ID','isbn':'ISBN','book_rating':'Book-Rating'},inplace=True)\n",
        "  ratings_df_unique = ratings_df.drop_duplicates(subset='ISBN')\n",
        "  train_df, test_df, interactions_full_df = get_train_test_split(ratings_df)\n",
        "  print(f'Interactions on Train set: %d' % len(train_df))\n",
        "  print(f'Interactions on Test set: %d' % len(test_df))\n",
        "\n",
        "  cf_preds_df = matrix_factorization_predictions(train_df)\n",
        "  cf_preds_df.head()\n",
        "  interactions_full_indexed_df = interactions_full_df.set_index('User-ID')\n",
        "  interactions_train_indexed_df = train_df.set_index('User-ID')\n",
        "  interactions_test_indexed_df = test_df.set_index('User-ID')\n",
        "  cf_recommender_model = CFRecommender(cf_preds_df)\n",
        "  model_recommender = ModelRecommender(interactions_full_indexed_df,interactions_test_indexed_df, interactions_train_indexed_df, ratings_df_unique)\n",
        "  calculate_rmse(test_df, cf_recommender_model)\n",
        "  return model_recommender, cf_recommender_model, test_df, train_df"
      ],
      "metadata": {
        "id": "ed7fM5HIP_Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_recommender, cf_recommender_model, test_df, train_df = build_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWS0xg-ASwQF",
        "outputId": "a0314a99-145f-4122-f1a4-b7b69cc9a932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of users: 16795\n",
            "Users with at least 3 interactions: 3451\n",
            "Total interactions: 46112\n",
            "Interactions from qualified users: 30359\n",
            "Unique user/item interactions: 30359\n",
            "Interactions on Train set: 21251\n",
            "Interactions on Test set: 9108\n",
            "Interactions on Train set: 21251\n",
            "Interactions on Test set: 9108\n",
            "RMSE: 1.160720057494315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books_based_on_mood(mood, user_id):\n",
        "  ret_updated_person_recs_df = model_recommender.recommend_book(cf_recommender_model,user_id,mood)\n",
        "  print(ret_updated_person_recs_df)\n",
        "  list_ret_updated_person_recs_df = list(ret_updated_person_recs_df['ISBN'])\n",
        "  list_ret_updated_person_recs_df = [number.zfill(10) for number in list_ret_updated_person_recs_df]\n",
        "  return list_ret_updated_person_recs_df"
      ],
      "metadata": {
        "id": "u0x4okRBQAew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print((recommend_books_based_on_mood('Motivational', 148744)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW5NpR45Qqp6",
        "outputId": "9383f55a-dea9-4f74-ac89-94f295bd8784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ISBN  recStrength      Max Mood                       Book\n",
            "26   446610399     4.528759  Motivational                 the rescue\n",
            "86   446356832     4.302083  Motivational          the sands of time\n",
            "136  553211684     4.229585  Motivational  tess of the d'urbervilles\n",
            "143  743211383     4.222939  Motivational               dreamcatcher\n",
            "148  451168364     4.221412  Motivational          nectar in a sieve\n",
            "['0446610399', '0446356832', '0553211684', '0743211383', '0451168364']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPvXe27XKd2Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}